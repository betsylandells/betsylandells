{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "under-lemon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f585b5c468b32f4d3b3e87a71b810873",
     "grade": false,
     "grade_id": "cell-179ae794a185f8b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Checkpoint 2\n",
    "### Due: Tuesday, 9 November, 2021 at 11:00am BST\n",
    "\n",
    "### Total points: 100\n",
    "\n",
    "### Read This First\n",
    "\n",
    "Wherever you see raise NotImplementedError(), remove that line and put your code there.\n",
    "\n",
    "Put the code that produces the output for a given task in the cell indicated. You are welcome to add as many cells as you like for imports, function definitions, variables, etc.\n",
    "\n",
    "Your notebook must run correctly when executed once from start to finish. Your notebook will be graded based on how it runs, not how it looks when you submit it. To test this, go to the Kernel menu and select Restart & Run All.\n",
    "\n",
    "Once you are happy with it, clear the output by selecting Restart & Clear Output from the Kernel menu.\n",
    "\n",
    "Submit through Noteable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-maryland",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2419240c2eb9553dd99b1641212f0fc5",
     "grade": false,
     "grade_id": "cell-0b6698cfafd847dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 1 (20 points)\n",
    "\n",
    "The first task is to find the number of local minima of the function in different number of dimensions ( from 1 to 5 inclusive). Your code should return the list or array of 5 integer values.\n",
    "\n",
    "The number of local minima for ndim = 1 should be 4. All the minimima should be within -10..10 range and there are no minima separated by less than 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-impression",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ceefbe23bc6efc70ff431aaa3279c8",
     "grade": false,
     "grade_id": "cell-193fa5b6b82a2a35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-career",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "304aed0aad772aa1f83f7f7435ee0776",
     "grade": false,
     "grade_id": "cell-aa6033a13e16d38b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "D = np.load('data.npz')['D']\n",
    "dims = [1, 2, 3, 4, 5]\n",
    "import scipy.special as ssp\n",
    "\n",
    "def blackbox_func(p):\n",
    "    \"\"\"\n",
    "    This is is the function that you need to optimize\n",
    "    DO NOT CHANGE THE CODE INSIDE THIS FUNCTION\n",
    "    \"\"\"\n",
    "    ndim = len(p)\n",
    "    pos = dims.index(ndim)\n",
    "    curD = D[10000 * pos:10000 * (pos + 1), :ndim]\n",
    "    return -ssp.logsumexp(np.sum(-0.5 * ((p[None, :] - curD) / .3)**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-ferry",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "304aed0aad772aa1f83f7f7435ee0776",
     "grade": false,
     "grade_id": "cell-aa6033a13e16d38b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "D = np.load('data.npz')['D']\n",
    "dims = [1, 2, 3, 4, 5]\n",
    "import scipy.special as ssp\n",
    "\n",
    "def blackbox_func(p):\n",
    "    \"\"\"\n",
    "    This is is the function that you need to optimize\n",
    "    DO NOT CHANGE THE CODE INSIDE THIS FUNCTION\n",
    "    \"\"\"\n",
    "    ndim = len(p)\n",
    "    pos = dims.index(ndim)\n",
    "    curD = D[10000 * pos:10000 * (pos + 1), :ndim]\n",
    "    return -ssp.logsumexp(np.sum(-0.5 * ((p[None, :] - curD) / .3)**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5391de4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "287fcd7b39230c089ad22203d641847c",
     "grade": true,
     "grade_id": "cell-4d36c746588f1de8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nminima():\n",
    "    n_minima = []\n",
    "    for n in dims:\n",
    "        #minimima within -10..10 range, seperated by 0.01 (which gives 200 divisions)\n",
    "        x = np.linspace(-10,10,200)\n",
    "        #initialize empty lists\n",
    "        minima = []\n",
    "        results = []\n",
    "        #iterating over the 200 starting points\n",
    "        for i in range(200):\n",
    "            #get the starting points in dimensions of the problem, n dimensions\n",
    "            x0 = x[i]*np.ones(n)\n",
    "            #mimize function for different starting points\n",
    "            res = scipy.optimize.minimize(blackbox_func, x0, method='Nelder-Mead')\n",
    "            #generate a results vector full of minima of the function\n",
    "            results.append(res.x[0])\n",
    "    \n",
    "        resultsArray = np.array(results)\n",
    "        #to get the unique minima that are seperated by 0.01 or more, round results to 2dp and get non repeated minima results\n",
    "        minima.append(np.unique(resultsArray.round(decimals=2)))\n",
    "        #the number of minima in the given dimension is given by the length of the unique minima vector\n",
    "        min_in_dims = len(minima[0])\n",
    "        #generate a list of the number of minima for each dimension\n",
    "        n_minima.append(min_in_dims)\n",
    "    return n_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function takes approx 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ed18a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af643653b50769a360a5acf225f17493",
     "grade": true,
     "grade_id": "cell-306cce0c0780fe5a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (len(find_nminima()) == 5)\n",
    "assert ((find_nminima()[0]) == 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c9452",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cb8104f89acfc8d86a8033274b0d6f5",
     "grade": false,
     "grade_id": "cell-9ffb52dbaa1b00f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 2 (20 pts)\n",
    "\n",
    "Generate random numbers from a probability distribution that looks like two triangles. \n",
    "The PDF f(x) is the following. Use the inverse CDF sampling method.\n",
    "* f(x) = 0 when x<0\n",
    "* f(x)= x/2 when 0<x<=1\n",
    "* f(x)= 1-x/2 when 1<x<=2\n",
    "* f(x)= 0 when 2<x<=3\n",
    "* f(x)= (x-3)/2 when 3<x<4\n",
    "* f(x)= (5-x)/2 when 4<x<5\n",
    "* f(x)= 0 when x>=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-porcelain",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Calculations of the inverse CDF were done on pen and paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-trunk",
   "metadata": {},
   "source": [
    "### integrating PDF f(x) to get CDF:\n",
    "CDF:\n",
    "1. F(X) = x^2/4 0<x<=1\n",
    "2. F(X) = -0.5 + x - x^2/4 1<x<=2\n",
    "3. F(X) = (x^2 - 6x + 10)/4 3<x<4\n",
    "4. F(X) = (10x - x^2 -23)/4 4<x<5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-ministry",
   "metadata": {},
   "source": [
    "### INVERTING CDF TO GET INVERSE CDF:\n",
    "INV CDF:\n",
    "- F-1(y) = sqrt(4y) 0<y<=0.25\n",
    "- F-1(y) = 2 - sqrt(8-16y))/2 0.25<y<=0.5\n",
    "- F-1(y) = 3 + sqrt(-8+16y)/2 0.5<y<0.75\n",
    "- F-1(y) = 5 - sqrt(16-16y)/2 0.75<y<1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa1cca",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1183d1c0deba4ac7c7d8d2e1d87279aa",
     "grade": true,
     "grade_id": "cell-15da3ad7914fbcff",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_triangles(N):\n",
    "    \"\"\" Return a numpy array with the length N with \n",
    "    random numbers following the distribution specified\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #generate a random uniform distribution of numbers\n",
    "    ys = np.random.uniform(size=N)\n",
    "    xs = 0*ys\n",
    "    \n",
    "    #equations for the inverse cdf for the given y limits as described above\n",
    "    xs[ys<=0.25] = np.sqrt(4 * ys[ys <= 0.25]) #x at 0 to 1\n",
    "    xs[(ys>0.25) & (ys<=0.5)] = 2 - np.sqrt(8-16*ys[(ys>0.25) & (ys<=0.5)])/2 #x at 1 to 2\n",
    "    xs[(ys>0.5) & (ys<0.75)] = 3 + np.sqrt(-8+16*ys[(ys>0.5) & (ys<0.75)])/2 #x at 3 to 4\n",
    "    xs[ys>0.75] = 5 - np.sqrt(16-16*ys[ys>0.75])/2 #x at 4 to 5\n",
    "    \n",
    "    return xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb031e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06088c11054d15c592fbba7b9dd1a122",
     "grade": true,
     "grade_id": "cell-1c23cb379bb25164",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The code will be tested by this\n",
    "plt.hist(generate_triangles(100000), bins=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa5064",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34242f08e117a74ec59231f2e2e29cdb",
     "grade": false,
     "grade_id": "cell-08472b87802d9f84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3 (20 pts)\n",
    "\n",
    "The motion of bodies in the Solar system can be described by the Kepler equation \n",
    "$$2 \\pi t/T = E - e \\sin(E)$$\n",
    "Where e is orbit eccentricity, t is the time of observation, T is the orbital period. And E is the so-called eccentric anomaly. \n",
    "If you know the eccentric anomaly E then the position of the body in the plane of the solar system can be described by \n",
    "$$x= a  (\\cos E -e) $$\n",
    "$$y= b \\sin E $$\n",
    "where a, b are the semi-major axis and semi-minor axis respectively.\n",
    "\n",
    "Your task is to write the function that determines the uncertainty on the position x given the time of observation, ecentricity, period, semi-major axis and their uncertainties.\n",
    "You can assume that for the eccentric anomaly E will be always between -1000 and 1000.\n",
    "We will verify that the errors are accurate to within 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a72e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b7f9026bce3db3531aeab832b1d0196",
     "grade": true,
     "grade_id": "cell-409d2d8c0ae7f7cf",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def kepler_uncert(t=None, T=None, e=None, a=None, err_t=None, err_T=None, err_e=None, err_a=None):\n",
    "    # return the value of the uncertainty on the x position of the solar system body\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #this is the size of the distribution\n",
    "    N = 1000\n",
    "    \n",
    "    #generate a normal distribution for variables t,T,e and a. This is given by their mean and error as inputted by the user\n",
    "    t_time = np.random.normal(t,err_t,size=N)\n",
    "    T_orbit = np.random.normal(T,err_T,size=N)\n",
    "    e_ecc = np.random.normal(e,err_e,size=N)\n",
    "    a = np.random.normal(a,err_a,size=N)\n",
    "    \n",
    "    #we need to estimate eccentric anomaly E as it cannot be solved analytically\n",
    "    #I estimated the mean E to be when sin = 0, therefore E = 2pi * t/T\n",
    "    mean_E = 2*np.pi*t/T\n",
    "    #since sin oscillates between -1 and 1, I estimated the deviation in E from its mean is given as +/- e\n",
    "    #I calculate the error to be the standard deviation over the square root of N\n",
    "    err_E = e/np.sqrt(N)\n",
    "    Es = np.random.normal(mean_E, err_E, size=N)\n",
    "    \n",
    "    x = a*(np.cos(Es) - e_ecc)\n",
    "    return x.std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the value of the second calculation should be around 0.106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-wedding",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6258dfb6b2854899ab5cd7ef10e94f30",
     "grade": true,
     "grade_id": "cell-b374622347044204",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(kepler_uncert(t=1, T=2, e=.5, a=3, err_t=1e-5, err_T=1e-4, err_e=1e-3, err_a=0.01))\n",
    "# This value should be close to 0.015\n",
    "\n",
    "print(kepler_uncert(t=3, T=4, e=.4, a=6, err_t=1e-4, err_T=1e-3, err_e=1e-2, err_a=0.02))\n",
    "# This should be close to 0.048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660068d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6258dfb6b2854899ab5cd7ef10e94f30",
     "grade": true,
     "grade_id": "cell-b374622347044204",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(kepler_uncert(t=1, T=2, e=.5, a=3, err_t=1e-5, err_T=1e-4, err_e=1e-3, err_a=0.01))\n",
    "# This value should be close to 0.015\n",
    "\n",
    "print(kepler_uncert(t=3, T=4, e=.4, a=6, err_t=1e-4, err_T=1e-3, err_e=1e-2, err_a=0.02))\n",
    "# This should be close to 0.048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd1541",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ae423ae112cf28943c0b4994c3f537b",
     "grade": false,
     "grade_id": "cell-87bfc105ba9092d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 4 (20 pts)\n",
    "\n",
    "# Fitting a periodic model to the data. \n",
    "\n",
    "In the input data checkpoint2_task4.txt. we have repeated measurements from the instrument. \n",
    "The file has 3 columns. One is the time of observation, the second one is the measurement, and the third one is the uncertainty of the measurement. \n",
    "We have reasons to believe that the measurement periodically change with time, so we want to fit the dataset provided by a periodic model \n",
    "$$M(x) = A \\sin(2\\pi x/T) + B \\cos(2\\pi x/T) $$\n",
    "in order to determine the period T from the data. A,B,T are model parameters\n",
    "\n",
    "Assuming that we know that the period should be between 0.5 and 5, determine the best period describing the data with the accuracy of better than 0.1.\n",
    "\n",
    "Your function needs to return the tuple with the best period and bestmodel values\n",
    "\n",
    "Hint: Use linear regression to fit the periodic models for a grid of periods. Select the period providing the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86208c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8c12d811c5c91103b1d0f27efd21b72",
     "grade": true,
     "grade_id": "cell-37dad26738d28bfe",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA = np.loadtxt('checkpoint2_task4.txt')\n",
    "\n",
    "plt.errorbar(DATA[0], DATA[1], DATA[2], fmt='.')\n",
    "\n",
    "#assign variable names to data columns\n",
    "xdata = DATA[0]\n",
    "ydata = DATA[1]\n",
    "sigma = DATA[2]\n",
    "\n",
    "def findper():\n",
    "    #periods between 0.5 and 5\n",
    "    periods = np.linspace(0.5,5,10000)\n",
    "    \n",
    "    #define model to be minimized (as given in the question above)\n",
    "    def Model(x,A,B):\n",
    "        return A*np.sin(2*np.pi*x/T) + B*np.cos(2*np.pi*x/T)\n",
    "    \n",
    "    #initialise empty lists of 1) fitted parameters and 2) chi squared values\n",
    "    y_fit = []\n",
    "    chi = []\n",
    "    \n",
    "    #fit the periodic models for a grid of periods\n",
    "    for T in periods:\n",
    "        #using the curve fitting, fit the model using the given data and initial guesses taken from experimenting with params\n",
    "        p_opt, p_cov = scipy.optimize.curve_fit(Model, xdata, ydata,p0=[2.83, 2])\n",
    "        #generate parameter errors to see if they're less than 0.1 (given in question)\n",
    "        p_err = np.sqrt(np.diag(p_cov))\n",
    "        #get A and B as the parameters\n",
    "        p_opt = p_opt.tolist()\n",
    "        A,B = p_opt\n",
    "        #also get the period that generates the model parameters\n",
    "        params = [p_opt, T, p_err]\n",
    "        #for each iteration add the parameters and period to the y_fit list\n",
    "        y_fit.append(params)\n",
    "        #generate chi squared values to see accuracy of the fit\n",
    "        chi.append(np.sum(np.square(((ydata-Model(xdata,A,B))/sigma))))\n",
    "        #get the optimum parameters by indexing y_fit where chi squared value is at a minimum\n",
    "        opt_params = y_fit[np.argmin(chi)]\n",
    "        \n",
    "    #get the best period, T\n",
    "    bestp = opt_params[1]\n",
    "    #generate the best model by using the optimal parameters\n",
    "    bestmod = opt_params[0][0]*np.sin(2*np.pi*xdata/bestp) + opt_params[0][1]*np.cos(2*np.pi*xdata/bestp)\n",
    "    \n",
    "    #check the chi squared value is reasonable\n",
    "    print('minimum chi squared value:',min(chi))\n",
    "    #check the paramater error is reasonable\n",
    "    print('parameters error:',opt_params[2])\n",
    "    \n",
    "    return bestp,bestmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2aa2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c76b8239c00df60e94d60b823aaa9e1",
     "grade": true,
     "grade_id": "cell-7aca6a3c20334962",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Your code will be tested with this \n",
    "plt.errorbar(DATA[0], DATA[1], DATA[2], fmt='.')\n",
    "bestp, bestmod = findper()\n",
    "print('BEST PERIOD', bestp)\n",
    "plt.plot(np.sort(DATA[0]), bestmod[np.argsort(DATA[0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fc5b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2181f2e89e018147727ccf5c4e28130c",
     "grade": false,
     "grade_id": "cell-09a8097b0427727e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 5 (20 pts)\n",
    "\n",
    "You are given a dataset from the particle physics experiment. \n",
    "In that experiment the number of particles are recorded in intervals of Energy.\n",
    "The dataset contains the array of those numbers and the center Energy of each bin/interval. \n",
    "We believe that the average number of particles in each bin could be described by  this model \n",
    "$$R(E) = A_1+ A_2 \\exp(A_3  E) + A_4  \\exp\n",
    "\\left( - \\frac{1}{2}\\frac{(x-A_5)^2}{A_6^2} \\right)$$\n",
    "\n",
    "where the first two terms are describing the background and the last term is a contribution from a decaying \n",
    "particle with the mean energy A5. This contribution creates a peak in the energy distribution. Your task is to measure A5.\n",
    "\n",
    "In the dataset you can assume that the number of particles in each bin is described by Poisson distribution with the rate described by the equantion above. You can assume that measurement of number of particles in each bin are independent from each other.\n",
    "\n",
    "Write the likelihood function and estimate the energy of the particle $A_5$ using maximum likelihood approach. \n",
    "Overplot your best model on top of the data and make sure it fits well. \n",
    "\n",
    "Determine the uncertainty of your measurement. Your function solve_task5() should return two numbers\n",
    "the estimate of the energy and its uncertainty. (If you don't know how to evaluate uncertainty, you can just return np.nan instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030b7c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2ce8fd702c5a99173e0a4436afa913e",
     "grade": false,
     "grade_id": "cell-96dc53b94f47084b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA = np.loadtxt('energy.txt', dtype=[('E', np.float64), ('N', int)])\n",
    "DATA['E']\n",
    "DATA['N']\n",
    "plt.plot(DATA['E'], DATA['N'], drawstyle='steps')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Number of particles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data to variable names E and N\n",
    "E = DATA['E']\n",
    "N = DATA['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rate equation as a function of parameters\n",
    "def rateeqn(E, a1, a2, a3, a4, a5, a6):\n",
    "    return a1 + a2*np.exp(a3*E)+a4*np.exp(-0.5*((E-a5)**2)/a6**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the negative log likelyhood function\n",
    "def get_NLL(a):    \n",
    "    #unpack unknown parameters a1 through a6\n",
    "    a1,a2,a3,a4,a5,a6 = a\n",
    "    LL = []\n",
    "    for i in range(len(E)):\n",
    "        #generate the mean, mu, by calculating rate equation for the different energies in dataset\n",
    "        mu = rateeqn(E[i],a1,a2,a3,a4,a5,a6)\n",
    "        #\"Assume that N in each bin is described by Poisson distribution with the rate described by the equantion above\"\n",
    "        #generate the log pmf of the poisson equation using the calculated mean\n",
    "        L = scipy.stats.poisson.logpmf(N[i], mu, loc=0)\n",
    "        #generate list of the log pmfs\n",
    "        LL.append(L)\n",
    "    #negative log likely hood is the negative of the sum over all log pmfs\n",
    "    NLL = -np.sum(LL)\n",
    "    return NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ca629",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eaf4d4a578e86b46390402017f93673",
     "grade": true,
     "grade_id": "cell-98749de728ce3694",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_task5():\n",
    "    \"\"\"\n",
    "    Your function needs to return the best period and the uncertainty. \n",
    "    It also needs to overplot the best model on top of the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #optimize the negative log likelyhood using minimize and generate the estimates for A\n",
    "    #get results '.x'\n",
    "    A = scipy.optimize.minimize(get_NLL,x0=[10,10,1,70,70,5]).x\n",
    "    #get the inverse hessian matrix, '.hess_inv'\n",
    "    HESS_INV = scipy.optimize.minimize(get_NLL,x0=[10,10,1,70,70,5]).hess_inv\n",
    "    \n",
    "    \n",
    "    #from documentation: '.hess_inv' returned by the fit is the covariance matrix describing the Gaussian approximation of LL\n",
    "    #he parameter errors are the root of the diag elements of hess_inv\n",
    "    errs = np.sqrt(np.diag(HESS_INV))\n",
    "    \n",
    "    #we want to return a5 and its error, which is A[4] and errs[4] (indexing starts at 0)\n",
    "    bestval = A[4]\n",
    "    besterr = errs[4]\n",
    "    \n",
    "    return bestval, besterr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-personality",
   "metadata": {},
   "source": [
    "##### Comments on initial guesses\n",
    "Initial guesses are chosen by looking at the distribution. `a1` and `a2` account for noise, which is around 20, so I assign them both a value of 10 each. `a3` is the exponential term, since there is not a peak from the noise, I assign it an arbritarily low number of 1. The next term describes a Gaussian distribution. `a4` is given by the height of the peak and `a5` given as the mean (centre of the peak) so I choose them to be 70. `a6` is the width of the peak which is around 5J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameter values from function using initial guesses\n",
    "A = scipy.optimize.minimize(get_NLL,x0=[10,10,1,70,70,5]).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Overplot your best model on top of the data and make sure it fits well\n",
    "plt.plot(DATA['E'], DATA['N'], drawstyle='steps')\n",
    "plt.plot(E,rateeqn(E, A[0], A[1], A[2], A[3], A[4], A[5]),'r')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Number of particles');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce7ce7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d61a3b5287a8fd8280860b2fa43374da",
     "grade": true,
     "grade_id": "cell-ffcc04bd9ef694c7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bestval, bessterr = solve_task5()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestval, bessterr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
